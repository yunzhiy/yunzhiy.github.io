{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_add_text(path, text, mode, org=[50, 50]):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    font = cv2.FONT_ITALIC\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "    text_size, baseline = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while success:\n",
    "        h, w = frame.shape[:2]\n",
    "        x, y = org\n",
    "        assert mode in [0, 1]\n",
    "        if mode == 0:\n",
    "            pass\n",
    "        else:\n",
    "            x = w - org[0] - text_size[0]\n",
    "\n",
    "        padd = 10\n",
    "        cv2.rectangle(frame, (x - padd, y - text_size[1] - padd), (x + text_size[0] + padd, y + padd), (255, 255, 255), thickness=cv2.FILLED)\n",
    "        cv2.putText(\n",
    "            img=frame,  \n",
    "            text=text,  \n",
    "            org=(x, y),  \n",
    "            fontFace=font, \n",
    "            fontScale=font_scale,  \n",
    "            color=(0, 0, 0),  \n",
    "            thickness=font_thickness,  \n",
    "        )\n",
    "        h, w = frame.shape[:2]\n",
    "        frames.append(frame[..., [2, 1, 0]])\n",
    "        \n",
    "        i += 1\n",
    "        success, frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "\n",
    "def image_add_text(path, text, mode, org=[50, 50]):\n",
    "    frame = cv2.imread(path)\n",
    "    \n",
    "    font = cv2.FONT_ITALIC\n",
    "    font_scale = 1\n",
    "    font_thickness = 2\n",
    "    text_size, baseline = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "   \n",
    "    h, w = frame.shape[:2]\n",
    "    x, y = org\n",
    "    assert mode in [0, 1]\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    else:\n",
    "        x = w - org[0] - text_size[0]\n",
    "\n",
    "    padd = 10\n",
    "    cv2.rectangle(frame, (x - padd, y - text_size[1] - padd), (x + text_size[0] + padd, y + padd), (255, 255, 255), thickness=cv2.FILLED)\n",
    "    cv2.putText(\n",
    "        img=frame,  \n",
    "        text=text,  \n",
    "        org=(x, y),  \n",
    "        fontFace=font, \n",
    "        fontScale=font_scale,  \n",
    "        color=(0, 0, 0),  \n",
    "        thickness=font_thickness,  \n",
    "    )\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = 'pose_opt/seq_23_no_opt_crop.mp4'\n",
    "# path2 = 'pose_opt/seq_23_crop.mp4'\n",
    "# path_out = 'pose_opt/seq_23_combine_crop.mp4'\n",
    "\n",
    "# path1 = 'pose_opt/seq_31_no_opt_crop.mp4'\n",
    "# path2 = 'pose_opt/seq_31_crop.mp4'\n",
    "# path_out = 'pose_opt/seq_31_combine_crop.mp4'\n",
    "\n",
    "# path1 = 'comparsion/seq_06_emernerf.mp4'\n",
    "# path2 = 'comparsion/seq_06.mp4'\n",
    "# path_out = 'comparsion/seq_06_combine.mp4'\n",
    "\n",
    "# path1 = 'comparsion/seq_25_emernerf.mp4'\n",
    "# path2 = 'comparsion/seq_25.mp4'\n",
    "# path_out = 'comparsion/seq_25_combine.mp4'\n",
    "\n",
    "path1 = 'decomposition/seq_04.mp4'\n",
    "path2 = 'decomposition/seq_04_bkgd.mp4'\n",
    "path_out = 'decomposition/seq_04_combine_bkgd.mp4'\n",
    "\n",
    "# path1 = 'decomposition/seq_17.mp4'\n",
    "# path2 = 'decomposition/seq_17_obj.mp4'\n",
    "# path_out = 'decomposition/seq_17_combine.mp4'\n",
    "\n",
    "\n",
    "# path1 = 'editing/seq05_original.mp4'\n",
    "# path2 = 'editing/seq05_editing.mp4'\n",
    "# path_out = 'editing/seq05_combine.mp4'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames1 = video_add_text(path1, 'Without Pose Optimization', 0)\n",
    "# frames2 = video_add_text(path2, 'With Pose Optimization', 1)\n",
    "# frames1 = video_add_text(path1, 'EmerNeRF', 0)\n",
    "# frames2 = video_add_text(path2, 'Ours', 1)\n",
    "frames1 = video_add_text(path1, 'Rendering', 0)\n",
    "frames2 = video_add_text(path2, 'Decomposition', 1)\n",
    "# frames1 = video_add_text(path1, 'Input', 0)\n",
    "# frames2 = video_add_text(path2, 'Editing', 1)\n",
    "frames = []\n",
    "for i in range(len(frames1)):\n",
    "    frame1, frame2 = frames1[i], frames2[i]\n",
    "    frame = np.concatenate([frame1, frame2], axis=1)\n",
    "    frames.append(frame)\n",
    "\n",
    "cap = cv2.VideoCapture(path1)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n",
    "\n",
    "imageio.mimwrite(path_out, frames, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 30.0\n",
      "Total Frames: 86\n",
      "Processed 0 frames out of 86\n",
      "Video to images conversion complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def video_to_images(input_video, output_folder):\n",
    "    # 创建输出文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "    # 获取视频的帧率和总帧数\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Video FPS: {fps}\")\n",
    "    print(f\"Total Frames: {total_frames}\")\n",
    "\n",
    "    # 逐帧读取视频并保存为图像文件\n",
    "    for frame_number in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error reading frame.\")\n",
    "            break\n",
    "\n",
    "        # 生成图像文件名\n",
    "        image_filename = os.path.join(output_folder, f\"frame_{frame_number:04d}.png\")\n",
    "\n",
    "        # 保存图像\n",
    "        cv2.imwrite(image_filename, frame)\n",
    "\n",
    "        # 显示进度\n",
    "        if frame_number % 100 == 0:\n",
    "            print(f\"Processed {frame_number} frames out of {total_frames}\")\n",
    "\n",
    "    # 释放视频对象\n",
    "    cap.release()\n",
    "\n",
    "    print(\"Video to images conversion complete.\")\n",
    "\n",
    "# 使用示例\n",
    "input_video_path = \"/Users/yanyunzhi/Research/project_page_assets/street_gaussians/editing/seq06_editing.mp4\"\n",
    "output_images_folder = \"/Users/yanyunzhi/Research/project_page_assets/street_gaussians/editing/seq06_editing\"\n",
    "\n",
    "video_to_images(input_video_path, output_images_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img1 = image_add_text('editing/seq05_original/frame_0146.png', text='Input', mode=0)\n",
    "# img2 = image_add_text('editing/seq05_editing/frame_0126.png', text='Editing', mode=1)\n",
    "# h, w = img2.shape[:2]\n",
    "# img1 = cv2.resize(img1, (w, h))\n",
    "# img = np.concatenate([img1, img2], axis=1)\n",
    "# cv2.imwrite('editing/seq05_combine_single.png', img)\n",
    "\n",
    "img1 = image_add_text('editing/seq06_original/frame_0077.png', text='Input', mode=0)\n",
    "img2 = image_add_text('editing/seq06_editing/frame_0077.png', text='Editing', mode=1)\n",
    "h, w = img2.shape[:2]\n",
    "img1 = cv2.resize(img1, (w, h))\n",
    "img = np.concatenate([img1, img2], axis=1)\n",
    "cv2.imwrite('editing/seq06_combine_single.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_path = '/Users/yanyunzhi/Research/project_page_assets/street_gaussians/editing/seq06_combine_single.png'\n",
    "video_output_path = '/Users/yanyunzhi/Research/project_page_assets/street_gaussians/editing/seq06_combine_single.mp4'\n",
    "img = cv2.imread(image_path)[..., [2, 1, 0]]\n",
    "frames = [img] * 10\n",
    "imageio.mimwrite(video_output_path, frames, fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = './waymo/'\n",
    "frames_all = []\n",
    "fps = 24\n",
    "for video_name in sorted(os.listdir(video_dir))[:4]:\n",
    "    video_path = os.path.join(video_dir, video_name)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        frames_all.append(frame[..., [2, 1, 0]])\n",
    "        success, frame = cap.read()\n",
    "\n",
    "frames_all = frames_all[5:]\n",
    "imageio.mimwrite('demo1.mp4', frames_all, fps=fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
